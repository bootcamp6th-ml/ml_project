{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3119aa",
   "metadata": {
    "id": "8f3119aa"
   },
   "source": [
    "## Machine Learning 프로젝트 수행을 위한 코드 구조화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7610ea",
   "metadata": {
    "id": "9f7610ea"
   },
   "source": [
    "- ML project를 위해서 사용하는 템플릿 코드를 만듭니다.\n",
    "\n",
    "1. **필요한 라이브러리와 데이터를 불러옵니다.**\n",
    "\n",
    "\n",
    "2. **EDA를 수행합니다.** 이 때 EDA의 목적은 풀어야하는 문제를 위해서 수행됩니다.\n",
    "\n",
    "\n",
    "3. **전처리를 수행합니다.** 이 때 중요한건 **feature engineering**을 어떻게 하느냐 입니다.\n",
    "\n",
    "\n",
    "4. **데이터 분할을 합니다.** 이 때 train data와 test data 간의 분포 차이가 없는지 확인합니다.\n",
    "\n",
    "\n",
    "5. **학습을 진행합니다.** 어떤 모델을 사용하여 학습할지 정합니다. 성능이 잘 나오는 GBM을 추천합니다.\n",
    "\n",
    "\n",
    "6. **hyper-parameter tuning을 수행합니다.** 원하는 목표 성능이 나올 때 까지 진행합니다. 검증 단계를 통해 지속적으로 **overfitting이 되지 않게 주의**하세요.\n",
    "\n",
    "\n",
    "7. **최종 테스트를 진행합니다.** 데이터 분석 대회 포맷에 맞는 submission 파일을 만들어서 성능을 확인해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f7530",
   "metadata": {
    "id": "bd2f7530"
   },
   "source": [
    "## 1. 라이브러리, 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "125fc348",
   "metadata": {
    "id": "125fc348"
   },
   "outputs": [],
   "source": [
    "# 데이터분석 4종 세트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 모델들, 성능 평가\n",
    "# (저는 일반적으로 정형데이터로 머신러닝 분석할 때는 이 2개 모델은 그냥 돌려봅니다. 특히 RF가 테스트하기 좋습니다.)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# KFold(CV), partial : optuna를 사용하기 위함\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from functools import partial\n",
    "\n",
    "# hyper-parameter tuning을 위한 라이브러리, optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3615c24a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3615c24a",
    "outputId": "6dc93ad0-06c8-4ee0-a96d-8d9a5dd6ddaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101763, 25) (67842, 24) (67842, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 불러옵니다.\n",
    "base_path = '../../data/'\n",
    "# train = pd.read_csv(base_path + 'train.csv', index_col='id')\n",
    "# test = pd.read_csv(base_path + 'test.csv', index_col='id')\n",
    "train = pd.read_csv(base_path + 'train_f7.csv', index_col='id')\n",
    "test = pd.read_csv(base_path + 'test_f7.csv', index_col='id')\n",
    "submission = pd.read_csv(base_path + 'sample_submission.csv', index_col='id')\n",
    "print(train.shape, test.shape, submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "train['lOBlank_n'] = train['lOBlank_n'].astype('category')\n",
    "test['lOBlank_n'] = test['lOBlank_n'].astype('category')\n",
    "train['branchCount_n'] = train['branchCount_n'].astype('category')\n",
    "test['branchCount_n'] = test['branchCount_n'].astype('category')\n",
    "train['pure'] = train['pure'].astype('category')\n",
    "test['pure'] = test['pure'].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "train = train.drop(columns=['lOBlank_n', 'branchCount_n'])\n",
    "test = test.drop(columns=['lOBlank_n', 'branchCount_n'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 67842 entries, 101763 to 169604\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   loc                67842 non-null  float64 \n",
      " 1   v(g)               67842 non-null  float64 \n",
      " 2   ev(g)              67842 non-null  float64 \n",
      " 3   iv(g)              67842 non-null  float64 \n",
      " 4   n                  67842 non-null  float64 \n",
      " 5   v                  67842 non-null  float64 \n",
      " 6   l                  67842 non-null  float64 \n",
      " 7   d                  67842 non-null  float64 \n",
      " 8   i                  67842 non-null  float64 \n",
      " 9   e                  67842 non-null  float64 \n",
      " 10  b                  67842 non-null  float64 \n",
      " 11  t                  67842 non-null  float64 \n",
      " 12  lOCode             67842 non-null  int64   \n",
      " 13  lOComment          67842 non-null  int64   \n",
      " 14  lOBlank            67842 non-null  int64   \n",
      " 15  locCodeAndComment  67842 non-null  int64   \n",
      " 16  uniq_Op            67842 non-null  float64 \n",
      " 17  uniq_Opnd          67842 non-null  float64 \n",
      " 18  total_Op           67842 non-null  float64 \n",
      " 19  total_Opnd         67842 non-null  float64 \n",
      " 20  branchCount        67842 non-null  float64 \n",
      " 21  pure               67842 non-null  category\n",
      "dtypes: category(1), float64(17), int64(4)\n",
      "memory usage: 11.5 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "c9c9acb8",
   "metadata": {
    "id": "c9c9acb8"
   },
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf620b",
   "metadata": {
    "id": "6fdf620b"
   },
   "source": [
    "- 데이터에서 찾아야 하는 기초적인 내용들을 확인합니다.\n",
    "\n",
    "\n",
    "- class imbalance, target distribution, outlier, correlation을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train.columns"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1TxMunIv4zb",
    "outputId": "56e20880-07fb-4f2a-c614-ef0c3202a0d0"
   },
   "id": "R1TxMunIv4zb",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['loc', 'v(g)', 'ev(g)', 'iv(g)', 'n', 'v', 'l', 'd', 'i', 'e', 'b', 't',\n       'lOCode', 'lOComment', 'lOBlank', 'locCodeAndComment', 'uniq_Op',\n       'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount', 'defects',\n       'pure'],\n      dtype='object')"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 101763 entries, 0 to 101762\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   loc                101763 non-null  float64 \n",
      " 1   v(g)               101763 non-null  float64 \n",
      " 2   ev(g)              101763 non-null  float64 \n",
      " 3   iv(g)              101763 non-null  float64 \n",
      " 4   n                  101763 non-null  float64 \n",
      " 5   v                  101763 non-null  float64 \n",
      " 6   l                  101763 non-null  float64 \n",
      " 7   d                  101763 non-null  float64 \n",
      " 8   i                  101763 non-null  float64 \n",
      " 9   e                  101763 non-null  float64 \n",
      " 10  b                  101763 non-null  float64 \n",
      " 11  t                  101763 non-null  float64 \n",
      " 12  lOCode             101763 non-null  int64   \n",
      " 13  lOComment          101763 non-null  int64   \n",
      " 14  lOBlank            101763 non-null  int64   \n",
      " 15  locCodeAndComment  101763 non-null  int64   \n",
      " 16  uniq_Op            101763 non-null  float64 \n",
      " 17  uniq_Opnd          101763 non-null  float64 \n",
      " 18  total_Op           101763 non-null  float64 \n",
      " 19  total_Opnd         101763 non-null  float64 \n",
      " 20  branchCount        101763 non-null  float64 \n",
      " 21  defects            101763 non-null  bool    \n",
      " 22  pure               101763 non-null  category\n",
      "dtypes: bool(1), category(1), float64(17), int64(4)\n",
      "memory usage: 17.3 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "9dbb8802",
   "metadata": {
    "id": "9dbb8802"
   },
   "source": [
    "### 3. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a6f0a",
   "metadata": {
    "id": "b79a6f0a"
   },
   "source": [
    "#### 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497a2d8",
   "metadata": {
    "id": "f497a2d8"
   },
   "source": [
    "### 4. 학습 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "47306aaf",
   "metadata": {
    "id": "47306aaf"
   },
   "outputs": [],
   "source": [
    "# 첫번째 테스트용으로 사용하고, 실제 학습시에는 K-Fold CV를 사용합니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop(columns=['defects'])\n",
    "y = train.defects\n",
    "\n",
    "# for OOF-prediction split 5% of data as validation dataset.\n",
    "X_origin_train, X_origin_val, y_origin_train, y_origin_val = train_test_split(X, y, test_size=0.2, random_state=61, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "67efd2ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67efd2ee",
    "outputId": "a8a904f0-8109-4e87-b0d8-81d97dde4a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81410, 22) (81410,) (20353, 22) (20353,)\n",
      "0.2266429185603734 0.22664963396059548\n"
     ]
    }
   ],
   "source": [
    "print(X_origin_train.shape, y_origin_train.shape, X_origin_val.shape, y_origin_val.shape)\n",
    "print(y_origin_train.mean(), y_origin_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58056e51",
   "metadata": {
    "id": "58056e51"
   },
   "source": [
    "### 5. 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "39fd2515",
   "metadata": {
    "id": "39fd2515"
   },
   "outputs": [],
   "source": [
    "# 간단하게 LightGBM 테스트\n",
    "# 적당한 hyper-parameter 조합을 두었습니다. (항상 best는 아닙니다. 예시입니다.)\n",
    "model = LGBMClassifier(\n",
    "    n_jobs=-1,\n",
    "    random_state=61\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ddffa474",
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "ddffa474",
    "outputId": "4e723622-af5a-4fea-9cd4-dfcd3c65630a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting LightGBM...\n"
     ]
    },
    {
     "data": {
      "text/plain": "LGBMClassifier(random_state=61)",
      "text/html": "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=61)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=61)</pre></div></div></div></div></div>"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nFitting LightGBM...\")\n",
    "model.fit(X_origin_train, y_origin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6c8b0259",
   "metadata": {
    "id": "6c8b0259"
   },
   "outputs": [],
   "source": [
    "# metric은 그때마다 맞게 바꿔줘야 합니다.\n",
    "evaluation_metric = roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a6b39be5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6b39be5",
    "outputId": "2e2c256f-fe78-4deb-8fab-727306e3ffec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "Train Score : 0.6770\n",
      "Validation Score : 0.6668\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction\")\n",
    "pred_train = model.predict(X_origin_train)\n",
    "pred_val = model.predict(X_origin_val)\n",
    "\n",
    "\n",
    "train_score = evaluation_metric(y_origin_train, pred_train)\n",
    "val_score = evaluation_metric(y_origin_val, pred_val)\n",
    "\n",
    "print(\"Train Score : %.4f\" % train_score)\n",
    "print(\"Validation Score : %.4f\" % val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc755b17",
   "metadata": {
    "id": "bc755b17"
   },
   "source": [
    "### 6. Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "34ce4986",
   "metadata": {
    "id": "34ce4986"
   },
   "outputs": [],
   "source": [
    "def optimizer(trial, X, y, K):\n",
    "    # 조절할 hyper-parameter 조합을 적어줍니다.\n",
    "    max_depth = trial.suggest_int('max_depth', 15, 25)\n",
    "    num_leaves = trial.suggest_categorical('num_leaves', [32,64,128,256,512,])\n",
    "    min_child_samples = trial.suggest_int('min_child_samples', 20, 80)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.7)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 1023)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.005, 0.2)\n",
    "\n",
    "    # 원하는 모델을 지정합니다, optuna는 시간이 오래걸리기 때문에 저는 보통 RF로 일단 테스트를 해본 뒤에 LGBM을 사용합니다.\n",
    "    model = LGBMClassifier(\n",
    "        max_depth=max_depth,\n",
    "        num_leaves=num_leaves,\n",
    "        min_child_samples=min_child_samples,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=61,\n",
    "    )\n",
    "\n",
    "    # K-Fold Cross validation을 구현합니다.\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    losses = []\n",
    "\n",
    "    for train_idx, val_idx in folds.split(X, y):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        loss = evaluation_metric(y_val, preds)\n",
    "        losses.append(loss)\n",
    "\n",
    "    # K-Fold의 평균 loss값을 돌려줍니다.\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7150b210",
   "metadata": {
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7150b210",
    "outputId": "fa1c663f-0f17-4f21-8016-ac43d456666d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 01:18:13,737] A new study created in memory with name: no-name-a2835bb0-aec6-4eca-b9ed-c65742e997b3\n",
      "[I 2023-10-22 01:21:08,425] Trial 0 finished with value: 0.6597926124849756 and parameters: {'max_depth': 15, 'num_leaves': 512, 'min_child_samples': 62, 'colsample_bytree': 0.6736284279801933, 'n_estimators': 782, 'learning_rate': 0.006246376982764095}. Best is trial 0 with value: 0.6597926124849756.\n",
      "[I 2023-10-22 01:21:16,979] Trial 1 finished with value: 0.6581391994745622 and parameters: {'max_depth': 16, 'num_leaves': 32, 'min_child_samples': 68, 'colsample_bytree': 0.6274607434814146, 'n_estimators': 206, 'learning_rate': 0.1892416098459412}. Best is trial 0 with value: 0.6597926124849756.\n",
      "[I 2023-10-22 01:22:03,967] Trial 2 finished with value: 0.6553857967282035 and parameters: {'max_depth': 17, 'num_leaves': 64, 'min_child_samples': 20, 'colsample_bytree': 0.6517142897098358, 'n_estimators': 870, 'learning_rate': 0.09789585354555999}. Best is trial 0 with value: 0.6597926124849756.\n",
      "[I 2023-10-22 01:22:35,531] Trial 3 finished with value: 0.652146878100872 and parameters: {'max_depth': 19, 'num_leaves': 64, 'min_child_samples': 29, 'colsample_bytree': 0.6448427279077364, 'n_estimators': 611, 'learning_rate': 0.16984697034221036}. Best is trial 0 with value: 0.6597926124849756.\n",
      "[I 2023-10-22 01:23:08,730] Trial 4 finished with value: 0.6534114180891188 and parameters: {'max_depth': 19, 'num_leaves': 256, 'min_child_samples': 49, 'colsample_bytree': 0.5221719580843716, 'n_estimators': 314, 'learning_rate': 0.17112241370806577}. Best is trial 0 with value: 0.6597926124849756.\n",
      "[W 2023-10-22 01:23:17,928] Trial 5 failed with parameters: {'max_depth': 19, 'num_leaves': 128, 'min_child_samples': 80, 'colsample_bytree': 0.5287164402244591, 'n_estimators': 431, 'learning_rate': 0.1550076004775968} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dukim\\AppData\\Local\\Temp\\ipykernel_5160\\108540893.py\", line 32, in optimizer\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\engine.py\", line 292, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\basic.py\", line 3021, in update\n",
      "    _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-22 01:23:17,943] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[211], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m opt_func \u001B[38;5;241m=\u001B[39m partial(optimizer, X\u001B[38;5;241m=\u001B[39mX_origin_train, y\u001B[38;5;241m=\u001B[39my_origin_train, K\u001B[38;5;241m=\u001B[39mK)\n\u001B[0;32m      4\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m# 최소/최대 어느 방향의 최적값을 구할 건지.\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopt_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\study.py:442\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    341\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    350\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    351\u001B[0m \n\u001B[0;32m    352\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 442\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    446\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    447\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    448\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    449\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[210], line 32\u001B[0m, in \u001B[0;36moptimizer\u001B[1;34m(trial, X, y, K)\u001B[0m\n\u001B[0;32m     29\u001B[0m X_val \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39miloc[val_idx, :]\n\u001B[0;32m     30\u001B[0m y_val \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39miloc[val_idx]\n\u001B[1;32m---> 32\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m preds \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_val)\n\u001B[0;32m     34\u001B[0m loss \u001B[38;5;241m=\u001B[39m evaluation_metric(y_val, preds)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\sklearn.py:967\u001B[0m, in \u001B[0;36mLGBMClassifier.fit\u001B[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[0;32m    964\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    965\u001B[0m             valid_sets[i] \u001B[38;5;241m=\u001B[39m (valid_x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_le\u001B[38;5;241m.\u001B[39mtransform(valid_y))\n\u001B[1;32m--> 967\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_sample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_class_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_class_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_init_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_init_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m            \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategorical_feature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcategorical_feature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001B[0m, in \u001B[0;36mLGBMModel.fit\u001B[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[0;32m    745\u001B[0m evals_result \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    746\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mappend(record_evaluation(evals_result))\n\u001B[1;32m--> 748\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    749\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    750\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    751\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_boost_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_estimators\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    752\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_sets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    753\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    755\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metrics_callable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    756\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    757\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    758\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[0;32m    759\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m evals_result:\n\u001B[0;32m    762\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evals_result \u001B[38;5;241m=\u001B[39m evals_result\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\engine.py:292\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cb \u001B[38;5;129;01min\u001B[39;00m callbacks_before_iter:\n\u001B[0;32m    285\u001B[0m     cb(callback\u001B[38;5;241m.\u001B[39mCallbackEnv(model\u001B[38;5;241m=\u001B[39mbooster,\n\u001B[0;32m    286\u001B[0m                             params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[0;32m    287\u001B[0m                             iteration\u001B[38;5;241m=\u001B[39mi,\n\u001B[0;32m    288\u001B[0m                             begin_iteration\u001B[38;5;241m=\u001B[39minit_iteration,\n\u001B[0;32m    289\u001B[0m                             end_iteration\u001B[38;5;241m=\u001B[39minit_iteration \u001B[38;5;241m+\u001B[39m num_boost_round,\n\u001B[0;32m    290\u001B[0m                             evaluation_result_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m--> 292\u001B[0m \u001B[43mbooster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    294\u001B[0m evaluation_result_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    295\u001B[0m \u001B[38;5;66;03m# check evaluation result.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\lightgbm\\basic.py:3021\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, train_set, fobj)\u001B[0m\n\u001B[0;32m   3019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_objective_to_none:\n\u001B[0;32m   3020\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LightGBMError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCannot update due to null objective function.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 3021\u001B[0m _safe_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLGBM_BoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3022\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3023\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_finished\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   3024\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__is_predicted_cur_iter \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__num_dataset)]\n\u001B[0;32m   3025\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m is_finished\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "K = 5   # Kfold 수\n",
    "opt_func = partial(optimizer, X=X_origin_train, y=y_origin_train, K=K)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\") # 최소/최대 어느 방향의 최적값을 구할 건지.\n",
    "study.optimize(opt_func, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0a118",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "72d0a118",
    "outputId": "978d6a99-5370-4b0e-c5f7-bb38fdde033b"
   },
   "outputs": [],
   "source": [
    "# optuna가 시도했던 모든 실험 관련 데이터\n",
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805da05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a805da05",
    "outputId": "bcd1a494-0422-474c-d9e8-3e48cddef25a"
   },
   "outputs": [],
   "source": [
    "print(\"Best Score: %.4f\" % study.best_value) # best score 출력\n",
    "print(\"Best params: \", study.best_trial.params) # best score일 때의 하이퍼파라미터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ae1eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "051ae1eb",
    "outputId": "58266f06-c9df-4dde-cafa-6c5a921f85fe"
   },
   "outputs": [],
   "source": [
    "# 실험 기록 시각화\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf8f65",
   "metadata": {
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "efbf8f65",
    "outputId": "7368048b-ad41-45ef-9350-cf7a16da295b"
   },
   "outputs": [],
   "source": [
    "# hyper-parameter들의 중요도\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b360ec",
   "metadata": {
    "id": "24b360ec"
   },
   "source": [
    "### 7. 테스트 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Make KFold OOF prediction\n",
    "def oof_preds(best_model, X, y, test):\n",
    "\n",
    "    # make KFold\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    final_preds = []\n",
    "    losses = []\n",
    "    oof = np.full(len(X), np.nan)\n",
    "    # fitting with best_model\n",
    "    for i, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        print(f\"========== Fold {i+1} ==========\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds = best_model.predict_proba(X_val)[:, 1]\n",
    "        oof[val_idx] = preds\n",
    "        test_preds = best_model.predict_proba(test)[:, 1]\n",
    "        final_preds.append(test_preds)\n",
    "        loss = evaluation_metric(y_val, preds)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Loss : {avg_loss:.4f}\")\n",
    "    return final_preds, oof"
   ],
   "metadata": {
    "id": "vbGPA_pvtJXf"
   },
   "id": "vbGPA_pvtJXf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test.info() # 결측치 없음."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWEElxsC7Gfl",
    "outputId": "f9f39b1c-fde5-47e7-e5b1-bbc0094e9cb0"
   },
   "id": "xWEElxsC7Gfl",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6787765",
   "metadata": {
    "id": "b6787765",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "outputId": "2876cc07-2f84-46b9-a06f-8058a88c1c59"
   },
   "outputs": [],
   "source": [
    "## X_test 만들기 : 앞서했던 전처리를 동일하게 적용해주면 됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0daf54e",
   "metadata": {
    "id": "a0daf54e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "90168fcf-9c4d-4a37-a83c-45ed45ba9997"
   },
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "\n",
    "# define best model\n",
    "best_model = LGBMClassifier(**best_params, random_state=61)\n",
    "\n",
    "# model finalization : 가장 일반적으로 좋은 예측 성능을 냈던 모델로, 전체 데이터 트레이닝.\n",
    "\n",
    "preds, oof = oof_preds(best_model, X, y, test)\n",
    "preds = np.mean(preds, axis=0)\n",
    "preds # 0.7913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2070c",
   "metadata": {
    "id": "8ff2070c"
   },
   "outputs": [],
   "source": [
    "submission['defects'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2c13f",
   "metadata": {
    "id": "55a2c13f"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(base_path+'preds/lightgbm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "oof_df = pd.DataFrame({\n",
    "    'lightgbm_oof': oof\n",
    "})\n",
    "oof_df.head()"
   ],
   "metadata": {
    "id": "QIgSFAdJ8oRh"
   },
   "id": "QIgSFAdJ8oRh",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oof_df.to_csv(base_path+'oof/lightgbm.csv',index_label='id', header=['lightgbm_oof'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame({'importance':best_model.feature_importances_,'column':test.columns}).sort_values(by='importance', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}