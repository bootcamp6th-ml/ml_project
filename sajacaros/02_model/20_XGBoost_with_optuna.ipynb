{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3119aa",
   "metadata": {
    "id": "8f3119aa"
   },
   "source": [
    "## Machine Learning 프로젝트 수행을 위한 코드 구조화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7610ea",
   "metadata": {
    "id": "9f7610ea"
   },
   "source": [
    "- ML project를 위해서 사용하는 템플릿 코드를 만듭니다.\n",
    "\n",
    "1. **필요한 라이브러리와 데이터를 불러옵니다.**\n",
    "\n",
    "\n",
    "2. **EDA를 수행합니다.** 이 때 EDA의 목적은 풀어야하는 문제를 위해서 수행됩니다.\n",
    "\n",
    "\n",
    "3. **전처리를 수행합니다.** 이 때 중요한건 **feature engineering**을 어떻게 하느냐 입니다.\n",
    "\n",
    "\n",
    "4. **데이터 분할을 합니다.** 이 때 train data와 test data 간의 분포 차이가 없는지 확인합니다.\n",
    "\n",
    "\n",
    "5. **학습을 진행합니다.** 어떤 모델을 사용하여 학습할지 정합니다. 성능이 잘 나오는 GBM을 추천합니다.\n",
    "\n",
    "\n",
    "6. **hyper-parameter tuning을 수행합니다.** 원하는 목표 성능이 나올 때 까지 진행합니다. 검증 단계를 통해 지속적으로 **overfitting이 되지 않게 주의**하세요.\n",
    "\n",
    "\n",
    "7. **최종 테스트를 진행합니다.** 데이터 분석 대회 포맷에 맞는 submission 파일을 만들어서 성능을 확인해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f7530",
   "metadata": {
    "id": "bd2f7530"
   },
   "source": [
    "## 1. 라이브러리, 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "125fc348",
   "metadata": {
    "id": "125fc348"
   },
   "outputs": [],
   "source": [
    "# 데이터분석 4종 세트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 모델들, 성능 평가\n",
    "# (저는 일반적으로 정형데이터로 머신러닝 분석할 때는 이 2개 모델은 그냥 돌려봅니다. 특히 RF가 테스트하기 좋습니다.)\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# KFold(CV), partial : optuna를 사용하기 위함\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from functools import partial\n",
    "\n",
    "# hyper-parameter tuning을 위한 라이브러리, optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3615c24a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3615c24a",
    "outputId": "6dc93ad0-06c8-4ee0-a96d-8d9a5dd6ddaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101763, 25) (67842, 24) (67842, 1)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 불러옵니다.\n",
    "base_path = '../../data/'\n",
    "# train = pd.read_csv(base_path + 'train.csv', index_col='id')\n",
    "# test = pd.read_csv(base_path + 'test.csv', index_col='id')\n",
    "train = pd.read_csv(base_path + 'train_f7.csv', index_col='id')\n",
    "test = pd.read_csv(base_path + 'test_f7.csv', index_col='id')\n",
    "submission = pd.read_csv(base_path + 'sample_submission.csv', index_col='id')\n",
    "print(train.shape, test.shape, submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "train['lOBlank_n'] = train['lOBlank_n'].astype('category')\n",
    "test['lOBlank_n'] = test['lOBlank_n'].astype('category')\n",
    "train['branchCount_n'] = train['branchCount_n'].astype('category')\n",
    "test['branchCount_n'] = test['branchCount_n'].astype('category')\n",
    "train['pure'] = train['pure'].astype('category')\n",
    "test['pure'] = test['pure'].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "train = train.drop(columns=['lOBlank_n', 'branchCount_n'])\n",
    "test = test.drop(columns=['lOBlank_n', 'branchCount_n'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "c9c9acb8",
   "metadata": {
    "id": "c9c9acb8"
   },
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf620b",
   "metadata": {
    "id": "6fdf620b"
   },
   "source": [
    "- 데이터에서 찾아야 하는 기초적인 내용들을 확인합니다.\n",
    "\n",
    "\n",
    "- class imbalance, target distribution, outlier, correlation을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train.columns"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R1TxMunIv4zb",
    "outputId": "56e20880-07fb-4f2a-c614-ef0c3202a0d0"
   },
   "id": "R1TxMunIv4zb",
   "execution_count": 140,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['loc', 'v(g)', 'ev(g)', 'iv(g)', 'n', 'v', 'l', 'd', 'i', 'e', 'b', 't',\n       'lOCode', 'lOComment', 'lOBlank', 'locCodeAndComment', 'uniq_Op',\n       'uniq_Opnd', 'total_Op', 'total_Opnd', 'branchCount', 'defects',\n       'pure'],\n      dtype='object')"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 101763 entries, 0 to 101762\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   loc                101763 non-null  float64 \n",
      " 1   v(g)               101763 non-null  float64 \n",
      " 2   ev(g)              101763 non-null  float64 \n",
      " 3   iv(g)              101763 non-null  float64 \n",
      " 4   n                  101763 non-null  float64 \n",
      " 5   v                  101763 non-null  float64 \n",
      " 6   l                  101763 non-null  float64 \n",
      " 7   d                  101763 non-null  float64 \n",
      " 8   i                  101763 non-null  float64 \n",
      " 9   e                  101763 non-null  float64 \n",
      " 10  b                  101763 non-null  float64 \n",
      " 11  t                  101763 non-null  float64 \n",
      " 12  lOCode             101763 non-null  int64   \n",
      " 13  lOComment          101763 non-null  int64   \n",
      " 14  lOBlank            101763 non-null  int64   \n",
      " 15  locCodeAndComment  101763 non-null  int64   \n",
      " 16  uniq_Op            101763 non-null  float64 \n",
      " 17  uniq_Opnd          101763 non-null  float64 \n",
      " 18  total_Op           101763 non-null  float64 \n",
      " 19  total_Opnd         101763 non-null  float64 \n",
      " 20  branchCount        101763 non-null  float64 \n",
      " 21  defects            101763 non-null  bool    \n",
      " 22  pure               101763 non-null  category\n",
      "dtypes: bool(1), category(1), float64(17), int64(4)\n",
      "memory usage: 17.3 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "9dbb8802",
   "metadata": {
    "id": "9dbb8802"
   },
   "source": [
    "### 3. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a6f0a",
   "metadata": {
    "id": "b79a6f0a"
   },
   "source": [
    "#### 결측치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497a2d8",
   "metadata": {
    "id": "f497a2d8"
   },
   "source": [
    "### 4. 학습 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "47306aaf",
   "metadata": {
    "id": "47306aaf"
   },
   "outputs": [],
   "source": [
    "# 첫번째 테스트용으로 사용하고, 실제 학습시에는 K-Fold CV를 사용합니다.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train.drop(columns=['defects'])\n",
    "y = train.defects\n",
    "\n",
    "# for OOF-prediction split 5% of data as validation dataset.\n",
    "X_origin_train, X_origin_val, y_origin_train, y_origin_val = train_test_split(X, y, test_size=0.2, random_state=61, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "67efd2ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67efd2ee",
    "outputId": "a8a904f0-8109-4e87-b0d8-81d97dde4a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81410, 22) (81410,) (20353, 22) (20353,)\n",
      "0.2266429185603734 0.22664963396059548\n"
     ]
    }
   ],
   "source": [
    "print(X_origin_train.shape, y_origin_train.shape, X_origin_val.shape, y_origin_val.shape)\n",
    "print(y_origin_train.mean(), y_origin_val.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58056e51",
   "metadata": {
    "id": "58056e51"
   },
   "source": [
    "### 5. 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "39fd2515",
   "metadata": {
    "id": "39fd2515"
   },
   "outputs": [],
   "source": [
    "# 간단하게 LightGBM 테스트\n",
    "# 적당한 hyper-parameter 조합을 두었습니다. (항상 best는 아닙니다. 예시입니다.)\n",
    "model = XGBClassifier(\n",
    "    booster='gbtree',\n",
    "    objective='binary:logistic',\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    random_state=61,\n",
    "    tree_method='hist',\n",
    "    enable_categorical=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ddffa474",
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "ddffa474",
    "outputId": "4e723622-af5a-4fea-9cd4-dfcd3c65630a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting LightGBM...\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=True, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n              predictor=None, random_state=61, ...)",
      "text/html": "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=True, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n              predictor=None, random_state=61, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, early_stopping_rounds=None,\n              enable_categorical=True, eval_metric=None, feature_types=None,\n              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n              predictor=None, random_state=61, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nFitting LightGBM...\")\n",
    "model.fit(X_origin_train, y_origin_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c8b0259",
   "metadata": {
    "id": "6c8b0259"
   },
   "outputs": [],
   "source": [
    "# metric은 그때마다 맞게 바꿔줘야 합니다.\n",
    "evaluation_metric = roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a6b39be5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6b39be5",
    "outputId": "2e2c256f-fe78-4deb-8fab-727306e3ffec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "Train Score : 0.6803\n",
      "Validation Score : 0.6661\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction\")\n",
    "pred_train = model.predict(X_origin_train)\n",
    "pred_val = model.predict(X_origin_val)\n",
    "\n",
    "\n",
    "train_score = evaluation_metric(y_origin_train, pred_train)\n",
    "val_score = evaluation_metric(y_origin_val, pred_val)\n",
    "\n",
    "print(\"Train Score : %.4f\" % train_score)\n",
    "print(\"Validation Score : %.4f\" % val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc755b17",
   "metadata": {
    "id": "bc755b17"
   },
   "source": [
    "### 6. Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "34ce4986",
   "metadata": {
    "id": "34ce4986"
   },
   "outputs": [],
   "source": [
    "def optimizer(trial, X, y, K):\n",
    "    # 조절할 hyper-parameter 조합을 적어줍니다.\n",
    "    max_depth = trial.suggest_int('max_depth', 5, 15)\n",
    "    colsample_bynode = trial.suggest_float('colsample_bynode', 0.5, 0.8)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0.5, 5.0)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 2000)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3)\n",
    "\n",
    "    # 원하는 모델을 지정합니다, optuna는 시간이 오래걸리기 때문에 저는 보통 RF로 일단 테스트를 해본 뒤에 LGBM을 사용합니다.\n",
    "    model = XGBClassifier(\n",
    "        max_depth=max_depth,\n",
    "        colsample_bynode=colsample_bynode,\n",
    "        reg_lambda=reg_lambda,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        random_state=61,\n",
    "        tree_method='hist',\n",
    "        enable_categorical=True,\n",
    "    )\n",
    "\n",
    "    # K-Fold Cross validation을 구현합니다.\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    losses = []\n",
    "\n",
    "    for train_idx, val_idx in folds.split(X, y):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        loss = evaluation_metric(y_val, preds)\n",
    "        losses.append(loss)\n",
    "\n",
    "\n",
    "    # K-Fold의 평균 loss값을 돌려줍니다.\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7150b210",
   "metadata": {
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7150b210",
    "outputId": "fa1c663f-0f17-4f21-8016-ac43d456666d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-22 01:09:04,057] A new study created in memory with name: no-name-b4de88cc-791c-430d-ba51-540706db3191\n",
      "[I 2023-10-22 01:09:31,482] Trial 0 finished with value: 0.6526959337744854 and parameters: {'max_depth': 11, 'colsample_bynode': 0.6612576800194273, 'reg_lambda': 4.359973629640399, 'n_estimators': 399, 'learning_rate': 0.20124170488945142}. Best is trial 0 with value: 0.6526959337744854.\n",
      "[I 2023-10-22 01:11:25,527] Trial 1 finished with value: 0.6498650476009434 and parameters: {'max_depth': 13, 'colsample_bynode': 0.7165078002533207, 'reg_lambda': 4.173099804960234, 'n_estimators': 1622, 'learning_rate': 0.0671564160992543}. Best is trial 0 with value: 0.6526959337744854.\n",
      "[I 2023-10-22 01:11:58,169] Trial 2 finished with value: 0.6525700594447577 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5499663958179583, 'reg_lambda': 3.303026944525973, 'n_estimators': 1570, 'learning_rate': 0.2344951814010577}. Best is trial 0 with value: 0.6526959337744854.\n",
      "[I 2023-10-22 01:13:51,978] Trial 3 finished with value: 0.6444817237212916 and parameters: {'max_depth': 14, 'colsample_bynode': 0.595129500855855, 'reg_lambda': 1.7002096340924573, 'n_estimators': 1958, 'learning_rate': 0.2324092753572382}. Best is trial 0 with value: 0.6526959337744854.\n",
      "[I 2023-10-22 01:14:39,779] Trial 4 finished with value: 0.6476018062916997 and parameters: {'max_depth': 15, 'colsample_bynode': 0.6593482146683519, 'reg_lambda': 2.988223611288735, 'n_estimators': 628, 'learning_rate': 0.2689115166143377}. Best is trial 0 with value: 0.6526959337744854.\n",
      "[I 2023-10-22 01:16:02,926] Trial 5 finished with value: 0.6462360597431973 and parameters: {'max_depth': 11, 'colsample_bynode': 0.7840246457938473, 'reg_lambda': 0.7232786983479802, 'n_estimators': 1858, 'learning_rate': 0.16946042865646246}. Best is trial 0 with value: 0.6526959337744854.\n",
      "[I 2023-10-22 01:16:59,456] Trial 6 finished with value: 0.6494013567855996 and parameters: {'max_depth': 12, 'colsample_bynode': 0.6298168872186082, 'reg_lambda': 4.033060189036087, 'n_estimators': 1102, 'learning_rate': 0.274727379244514}. Best is trial 0 with value: 0.6526959337744854.\n",
      "[I 2023-10-22 01:17:11,605] Trial 7 finished with value: 0.6587019558825273 and parameters: {'max_depth': 5, 'colsample_bynode': 0.6434206737967063, 'reg_lambda': 4.4936131763643985, 'n_estimators': 536, 'learning_rate': 0.15323520855209055}. Best is trial 7 with value: 0.6587019558825273.\n",
      "[I 2023-10-22 01:18:00,858] Trial 8 finished with value: 0.6488864474479523 and parameters: {'max_depth': 8, 'colsample_bynode': 0.6756212453473786, 'reg_lambda': 2.2221265718394596, 'n_estimators': 1666, 'learning_rate': 0.2264147359883226}. Best is trial 7 with value: 0.6587019558825273.\n",
      "[I 2023-10-22 01:18:46,041] Trial 9 finished with value: 0.6472878609813569 and parameters: {'max_depth': 15, 'colsample_bynode': 0.5962809393704611, 'reg_lambda': 4.5310646287645735, 'n_estimators': 555, 'learning_rate': 0.2618899222915107}. Best is trial 7 with value: 0.6587019558825273.\n",
      "[I 2023-10-22 01:18:50,713] Trial 10 finished with value: 0.6654343534799029 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5007340679145511, 'reg_lambda': 4.891766352045188, 'n_estimators': 92, 'learning_rate': 0.1075527448225074}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:18:54,032] Trial 11 finished with value: 0.6650526222567841 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5217380677627216, 'reg_lambda': 4.91860475404291, 'n_estimators': 107, 'learning_rate': 0.10702796481295809}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:18:58,054] Trial 12 finished with value: 0.6636105437342229 and parameters: {'max_depth': 8, 'colsample_bynode': 0.5002668590111075, 'reg_lambda': 4.949976226152131, 'n_estimators': 62, 'learning_rate': 0.09560236167224836}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:19:02,982] Trial 13 finished with value: 0.6628762143304158 and parameters: {'max_depth': 7, 'colsample_bynode': 0.5204279208541466, 'reg_lambda': 4.982657198063517, 'n_estimators': 99, 'learning_rate': 0.014171784738214913}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:19:26,096] Trial 14 finished with value: 0.6560063221098836 and parameters: {'max_depth': 6, 'colsample_bynode': 0.5493255582775265, 'reg_lambda': 3.6232593083721083, 'n_estimators': 937, 'learning_rate': 0.12191133390549129}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:19:36,589] Trial 15 finished with value: 0.660539767146827 and parameters: {'max_depth': 9, 'colsample_bynode': 0.5002657064577825, 'reg_lambda': 3.6945123374126236, 'n_estimators': 212, 'learning_rate': 0.07940765317946771}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:19:58,249] Trial 16 finished with value: 0.6574320961305331 and parameters: {'max_depth': 6, 'colsample_bynode': 0.5453575286699985, 'reg_lambda': 4.930857116894504, 'n_estimators': 888, 'learning_rate': 0.12336755595802165}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:20:08,638] Trial 17 finished with value: 0.6635801017074222 and parameters: {'max_depth': 7, 'colsample_bynode': 0.5729116912450052, 'reg_lambda': 3.7868029752928916, 'n_estimators': 311, 'learning_rate': 0.042793546171899136}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:20:31,499] Trial 18 finished with value: 0.6572215024968024 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5299701938097402, 'reg_lambda': 3.2502679419615705, 'n_estimators': 1229, 'learning_rate': 0.11313283468293694}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:21:01,616] Trial 19 finished with value: 0.6526960480418847 and parameters: {'max_depth': 9, 'colsample_bynode': 0.5003829442495071, 'reg_lambda': 4.574716422648844, 'n_estimators': 749, 'learning_rate': 0.1564786315857291}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:21:34,575] Trial 20 finished with value: 0.6576385316961607 and parameters: {'max_depth': 6, 'colsample_bynode': 0.5821747678767512, 'reg_lambda': 4.142271249253003, 'n_estimators': 1316, 'learning_rate': 0.058505775341990765}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:21:40,195] Trial 21 finished with value: 0.6627115468346024 and parameters: {'max_depth': 8, 'colsample_bynode': 0.5001055255601881, 'reg_lambda': 4.919453165488379, 'n_estimators': 76, 'learning_rate': 0.09205784334418918}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:21:52,126] Trial 22 finished with value: 0.6584337561670781 and parameters: {'max_depth': 7, 'colsample_bynode': 0.5269411389140995, 'reg_lambda': 4.672360146499068, 'n_estimators': 330, 'learning_rate': 0.1020690852880546}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:21:58,546] Trial 23 finished with value: 0.6618977273154554 and parameters: {'max_depth': 9, 'colsample_bynode': 0.5665957058195027, 'reg_lambda': 4.989445591357765, 'n_estimators': 88, 'learning_rate': 0.08953055289844139}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:22:08,797] Trial 24 finished with value: 0.6602035492087636 and parameters: {'max_depth': 5, 'colsample_bynode': 0.5240704644974746, 'reg_lambda': 4.188695774203291, 'n_estimators': 429, 'learning_rate': 0.13424285217752854}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:22:18,578] Trial 25 finished with value: 0.6598569714837426 and parameters: {'max_depth': 8, 'colsample_bynode': 0.550371228233004, 'reg_lambda': 4.60701143426042, 'n_estimators': 218, 'learning_rate': 0.10622397271723874}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:22:37,353] Trial 26 finished with value: 0.6566683028940721 and parameters: {'max_depth': 6, 'colsample_bynode': 0.5224276947355816, 'reg_lambda': 3.9335358206017954, 'n_estimators': 755, 'learning_rate': 0.1374078733241042}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:22:49,822] Trial 27 finished with value: 0.6592212881696641 and parameters: {'max_depth': 10, 'colsample_bynode': 0.5000221968521099, 'reg_lambda': 4.337956566210976, 'n_estimators': 200, 'learning_rate': 0.07683546581559782}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[I 2023-10-22 01:23:04,702] Trial 28 finished with value: 0.6609617675521353 and parameters: {'max_depth': 7, 'colsample_bynode': 0.6096251820058894, 'reg_lambda': 4.708336440116365, 'n_estimators': 444, 'learning_rate': 0.049305195792101845}. Best is trial 10 with value: 0.6654343534799029.\n",
      "[W 2023-10-22 01:23:20,368] Trial 29 failed with parameters: {'max_depth': 10, 'colsample_bynode': 0.5664975392025121, 'reg_lambda': 4.19977147811621, 'n_estimators': 292, 'learning_rate': 0.17309126401648067} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\dukim\\AppData\\Local\\Temp\\ipykernel_17968\\3281157305.py\", line 32, in optimizer\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\dukim\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-22 01:23:20,378] Trial 29 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[149], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m opt_func \u001B[38;5;241m=\u001B[39m partial(optimizer, X\u001B[38;5;241m=\u001B[39mX_origin_train, y\u001B[38;5;241m=\u001B[39my_origin_train, K\u001B[38;5;241m=\u001B[39mK)\n\u001B[0;32m      4\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m# 최소/최대 어느 방향의 최적값을 구할 건지.\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopt_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\study.py:442\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    341\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    350\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    351\u001B[0m \n\u001B[0;32m    352\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 442\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    446\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    447\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    448\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    449\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    451\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[148], line 32\u001B[0m, in \u001B[0;36moptimizer\u001B[1;34m(trial, X, y, K)\u001B[0m\n\u001B[0;32m     29\u001B[0m X_val \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39miloc[val_idx, :]\n\u001B[0;32m     30\u001B[0m y_val \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39miloc[val_idx]\n\u001B[1;32m---> 32\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     33\u001B[0m preds \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_val)\n\u001B[0;32m     34\u001B[0m loss \u001B[38;5;241m=\u001B[39m evaluation_metric(y_val, preds)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\sklearn.py:1490\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1462\u001B[0m (\n\u001B[0;32m   1463\u001B[0m     model,\n\u001B[0;32m   1464\u001B[0m     metric,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1469\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[0;32m   1470\u001B[0m )\n\u001B[0;32m   1471\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[0;32m   1472\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[0;32m   1473\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1487\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[0;32m   1488\u001B[0m )\n\u001B[1;32m-> 1490\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dmatrix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_num_boosting_rounds\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1495\u001B[0m \u001B[43m    \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1496\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevals_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevals_result\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1498\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1499\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1500\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxgb_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1501\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n\u001B[0;32m   1505\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective \u001B[38;5;241m=\u001B[39m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\training.py:185\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001B[0m\n\u001B[0;32m    183\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mbefore_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m--> 185\u001B[0m \u001B[43mbst\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cb_container\u001B[38;5;241m.\u001B[39mafter_iteration(bst, i, dtrain, evals):\n\u001B[0;32m    187\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ml_project\\lib\\site-packages\\xgboost\\core.py:1918\u001B[0m, in \u001B[0;36mBooster.update\u001B[1;34m(self, dtrain, iteration, fobj)\u001B[0m\n\u001B[0;32m   1915\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_dmatrix_features(dtrain)\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1918\u001B[0m     _check_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mXGBoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1919\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_int\u001B[49m\u001B[43m(\u001B[49m\u001B[43miteration\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1920\u001B[0m \u001B[43m                                            \u001B[49m\u001B[43mdtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1922\u001B[0m     pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(dtrain, output_margin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "K = 5   # Kfold 수\n",
    "opt_func = partial(optimizer, X=X_origin_train, y=y_origin_train, K=K)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\") # 최소/최대 어느 방향의 최적값을 구할 건지.\n",
    "study.optimize(opt_func, n_trials=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0a118",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "72d0a118",
    "outputId": "978d6a99-5370-4b0e-c5f7-bb38fdde033b"
   },
   "outputs": [],
   "source": [
    "# optuna가 시도했던 모든 실험 관련 데이터\n",
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805da05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a805da05",
    "outputId": "bcd1a494-0422-474c-d9e8-3e48cddef25a"
   },
   "outputs": [],
   "source": [
    "print(\"Best Score: %.4f\" % study.best_value) # best score 출력\n",
    "print(\"Best params: \", study.best_trial.params) # best score일 때의 하이퍼파라미터들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ae1eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "051ae1eb",
    "outputId": "58266f06-c9df-4dde-cafa-6c5a921f85fe"
   },
   "outputs": [],
   "source": [
    "# 실험 기록 시각화\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf8f65",
   "metadata": {
    "scrolled": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "efbf8f65",
    "outputId": "7368048b-ad41-45ef-9350-cf7a16da295b"
   },
   "outputs": [],
   "source": [
    "# hyper-parameter들의 중요도\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b360ec",
   "metadata": {
    "id": "24b360ec"
   },
   "source": [
    "### 7. 테스트 및 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Make KFold OOF prediction\n",
    "def oof_preds(best_model, X, y, test):\n",
    "\n",
    "    # make KFold\n",
    "    folds = StratifiedKFold(n_splits=K, random_state=61, shuffle=True)\n",
    "    final_preds = []\n",
    "    losses = []\n",
    "    oof = np.full(len(X), np.nan)\n",
    "    # fitting with best_model\n",
    "    for i, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        X_train = X.iloc[train_idx, :]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        X_val = X.iloc[val_idx, :]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        print(f\"========== Fold {i+1} ==========\")\n",
    "        best_model.fit(X_train, y_train)\n",
    "        preds = best_model.predict_proba(X_val)[:, 1]\n",
    "        oof[val_idx] = preds\n",
    "        test_preds = best_model.predict_proba(test)[:, 1]\n",
    "        final_preds.append(test_preds)\n",
    "        loss = evaluation_metric(y_val, preds)\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    avg_loss = np.mean(losses)\n",
    "    print(f\"Loss : {avg_loss:.4f}\")\n",
    "    return final_preds, oof"
   ],
   "metadata": {
    "id": "vbGPA_pvtJXf"
   },
   "id": "vbGPA_pvtJXf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test.info() # 결측치 없음."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xWEElxsC7Gfl",
    "outputId": "f9f39b1c-fde5-47e7-e5b1-bbc0094e9cb0"
   },
   "id": "xWEElxsC7Gfl",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6787765",
   "metadata": {
    "id": "b6787765",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "outputId": "2876cc07-2f84-46b9-a06f-8058a88c1c59"
   },
   "outputs": [],
   "source": [
    "## X_test 만들기 : 앞서했던 전처리를 동일하게 적용해주면 됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0daf54e",
   "metadata": {
    "id": "a0daf54e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "90168fcf-9c4d-4a37-a83c-45ed45ba9997"
   },
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "\n",
    "# define best model\n",
    "best_model = XGBClassifier(**best_params, random_state=61, tree_method='hist', enable_categorical=True,)\n",
    "\n",
    "# model finalization : 가장 일반적으로 좋은 예측 성능을 냈던 모델로, 전체 데이터 트레이닝.\n",
    "preds, oof = oof_preds(best_model, X, y, test)\n",
    "preds = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2070c",
   "metadata": {
    "id": "8ff2070c"
   },
   "outputs": [],
   "source": [
    "submission['defects'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2c13f",
   "metadata": {
    "id": "55a2c13f"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(base_path+'preds/xgboost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "oof_df = pd.DataFrame({\n",
    "    'xgboost_oof': oof\n",
    "})\n",
    "oof_df.head()"
   ],
   "metadata": {
    "id": "QIgSFAdJ8oRh"
   },
   "id": "QIgSFAdJ8oRh",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "oof_df.to_csv(base_path+'oof/xgboost.csv', index_label='id', header=['xgboost_oof'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.DataFrame({'importance':best_model.feature_importances_,'column':test.columns}).sort_values(by='importance', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}